{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb480bda-04d1-4e4c-89a1-a53e75051d52",
   "metadata": {},
   "source": [
    "# DATA MINING - WEEK 5\n",
    "## NGUYEN XUAN VIET DUC\n",
    "## 22280012 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883a00a-f697-466e-94c3-62ccc21a2232",
   "metadata": {},
   "source": [
    "### III. Practice content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6737eb-a7c0-44ce-8ec6-f0d8d8578992",
   "metadata": {},
   "source": [
    "#### 1. Using library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d18af9-6e55-4273-9f2e-4c6075710f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyECLAT\n",
      "  Downloading pyECLAT-1.0.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pandas>=0.25.3 (from pyECLAT)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m893.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.17.4 (from pyECLAT)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.41.1 (from pyECLAT)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/vietducspector/jupyter_env/lib/python3.12/site-packages (from pandas>=0.25.3->pyECLAT) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.25.3->pyECLAT)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=0.25.3->pyECLAT)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/vietducspector/jupyter_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->pyECLAT) (1.17.0)\n",
      "Downloading pyECLAT-1.0.2-py3-none-any.whl (6.3 kB)\n",
      "Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, tqdm, numpy, pandas, pyECLAT\n",
      "Successfully installed numpy-2.2.5 pandas-2.2.3 pyECLAT-1.0.2 pytz-2025.2 tqdm-4.67.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyECLAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a808e46b-4b25-4c38-bbca-2a0ef0725808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Chips</td>\n",
       "      <td>Bread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2       3     4      5\n",
       "0   Wine  Chips  Bread   Butter  Milk  Apple\n",
       "1   Wine    NaN  Bread   Butter  Milk    NaN\n",
       "2    NaN    NaN  Bread   Butter  Milk    NaN\n",
       "3    NaN  Chips     NaN     NaN   NaN  Apple\n",
       "4   Wine  Chips  Bread   Butter  Milk  Apple\n",
       "5   Wine  Chips     NaN     NaN  Milk    NaN\n",
       "6   Wine  Chips  Bread   Butter   NaN  Apple\n",
       "7   Wine  Chips     NaN     NaN  Milk    NaN\n",
       "8   Wine    NaN  Bread      NaN   NaN  Apple\n",
       "9   Wine    NaN  Bread   Butter  Milk    NaN\n",
       "10   NaN  Chips  Bread   Butter   NaN  Apple\n",
       "11  Wine    NaN     NaN  Butter  Milk  Apple\n",
       "12  Wine  Chips  Bread   Butter  Milk    NaN\n",
       "13  Wine    NaN  Bread      NaN  Milk  Apple\n",
       "14  Wine    NaN  Bread   Butter  Milk  Apple\n",
       "15  Wine  Chips  Bread   Butter  Milk  Apple\n",
       "16   NaN  Chips  Bread   Butter  Milk  Apple\n",
       "17   NaN  Chips     NaN  Butter  Milk  Apple\n",
       "18  Wine  Chips  Bread   Butter  Milk  Apple\n",
       "19  Wine    NaN  Bread   Butter  Milk  Apple\n",
       "20  Wine  Chips  Bread      NaN  Milk  Apple\n",
       "21   NaN  Chips     NaN     NaN   NaN    NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyECLAT import ECLAT\n",
    "\n",
    "data = pd.read_csv('data.csv', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435cb799-2eae-4eb1-9306-668589104c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6/6 [00:00<00:00, 193.58it/s]\n",
      "100%|██████████████████████████████████████████| 6/6 [00:00<00:00, 24941.35it/s]\n",
      "100%|████████████████████████████████████████████| 6/6 [00:00<00:00, 962.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Butter</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Bread</th>\n",
       "      <th>Chips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Wine  Butter  Milk  Apple  Bread   Chips\n",
       "0      1       1     1      1       1      1\n",
       "1      1       1     1      0       1      0\n",
       "2      0       1     1      0       1      0\n",
       "3      0       0     0      1       0      1\n",
       "4      1       1     1      1       1      1\n",
       "5      1       0     1      0       0      1\n",
       "6      1       1     0      1       1      1\n",
       "7      1       0     1      0       0      1\n",
       "8      1       0     0      1       1      0\n",
       "9      1       1     1      0       1      0\n",
       "10     0       1     0      1       1      1\n",
       "11     1       1     1      1       0      0\n",
       "12     1       1     1      0       1      1\n",
       "13     1       0     1      1       1      0\n",
       "14     1       1     1      1       1      0\n",
       "15     1       1     1      1       1      1\n",
       "16     0       1     1      1       1      1\n",
       "17     0       1     1      1       0      1\n",
       "18     1       1     1      1       1      1\n",
       "19     1       1     1      1       1      0\n",
       "20     1       0     1      1       1      1\n",
       "21     0       0     0      0       0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclat_instance = ECLAT(data=data, verbose=True)\n",
    "eclat_instance.df_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d068585d-a83b-4fa1-975a-eba4916e81fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 2 by 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 246.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 3 by 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 404.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 4 by 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 409.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 5 by 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 436.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 6 by 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 391.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wine &amp; Milk</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Item   Support\n",
       "0  Wine & Milk  0.636364"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_per_transaction = eclat_instance.df_bin.astype(int).sum(axis=1)\n",
    "min_support = 0.6\n",
    "min_combination = 2\n",
    "max_combination = max(items_per_transaction)\n",
    "rule_indices, rule_supports = eclat_instance.fit(min_support=min_support, \n",
    "                                                 min_combination=min_combination, \n",
    "                                                 max_combination=max_combination, \n",
    "                                                 separator=' & ', verbose=True)\n",
    "result = pd.DataFrame(rule_supports.items(), columns=['Item', 'Support'])\n",
    "result1=result.sort_values(by=['Support'], ascending=False)\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c0d8e-21a6-4fb4-94b7-ac00cdf6d02a",
   "metadata": {},
   "source": [
    "#### 2. Vertical Apriori from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2407f36-1b97-4f49-b6d6-af28a3c4cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from typing import Dict, List, Set, Tuple, Any\n",
    "\n",
    "\n",
    "class VerticalApriori:\n",
    "    def __init__(self, min_support: float = 0.5):\n",
    "        \"\"\"\n",
    "        Initialize the Vertical Apriori algorithm.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        min_support : float\n",
    "            Minimum support threshold (between 0 and 1)\n",
    "        \"\"\"\n",
    "        self.min_support = min_support\n",
    "        self.transactions_count = 0\n",
    "        self.freq_itemsets = []\n",
    "        self.tid_mapping = {}  # Item to transaction ID mapping\n",
    "\n",
    "    def _create_vertical_representation(self, dataset: List[List[Any]]) -> Dict[Any, Set[int]]:\n",
    "        \"\"\"\n",
    "        Convert horizontal dataset to vertical representation.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataset : List[List[Any]]\n",
    "            List of transactions where each transaction is a list of items\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Dict[Any, Set[int]]\n",
    "            Dictionary mapping items to sets of transaction IDs\n",
    "        \"\"\"\n",
    "        vertical_representation = defaultdict(set)\n",
    "        \n",
    "        for tid, transaction in enumerate(dataset):\n",
    "            for item in transaction:\n",
    "                vertical_representation[item].add(tid)\n",
    "        \n",
    "        return vertical_representation\n",
    "    \n",
    "    def _get_support(self, item_tids: Set[int]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate support for an itemset based on its transaction IDs.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        item_tids : Set[int]\n",
    "            Set of transaction IDs containing the itemset\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Support value\n",
    "        \"\"\"\n",
    "        return len(item_tids) / self.transactions_count\n",
    "    \n",
    "    def _generate_candidate_itemsets(self, prev_freq_itemsets: List[Tuple], k: int) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Generate candidate k-itemsets from (k-1)-itemsets.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        prev_freq_itemsets : List[Tuple]\n",
    "            List of frequent (k-1)-itemsets\n",
    "        k : int\n",
    "            Size of itemsets to generate\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        List[Tuple]\n",
    "            List of candidate k-itemsets\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        # Self-joining step\n",
    "        for i in range(len(prev_freq_itemsets)):\n",
    "            for j in range(i + 1, len(prev_freq_itemsets)):\n",
    "                # For k > 2, we join only if first k-2 elements are identical\n",
    "                if k > 2:\n",
    "                    if prev_freq_itemsets[i][:-1] == prev_freq_itemsets[j][:-1]:\n",
    "                        # Create new candidate by combining the two itemsets\n",
    "                        new_candidate = prev_freq_itemsets[i][:-1] + (prev_freq_itemsets[i][-1],) + (prev_freq_itemsets[j][-1],)\n",
    "                        candidates.append(new_candidate)\n",
    "                else:  # k == 2\n",
    "                    new_candidate = (prev_freq_itemsets[i][0], prev_freq_itemsets[j][0])\n",
    "                    candidates.append(new_candidate)\n",
    "        \n",
    "        # For k > 2, prune step: remove candidates with infrequent subsets\n",
    "        if k > 2:\n",
    "            pruned_candidates = []\n",
    "            for candidate in candidates:\n",
    "                should_prune = False\n",
    "                # Check if all k-1 subsets are frequent\n",
    "                for subset in combinations(candidate, k - 1):\n",
    "                    if subset not in prev_freq_itemsets:\n",
    "                        should_prune = True\n",
    "                        break\n",
    "                if not should_prune:\n",
    "                    pruned_candidates.append(candidate)\n",
    "            return pruned_candidates\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def _get_transaction_ids(self, itemset: Tuple) -> Set[int]:\n",
    "        \"\"\"\n",
    "        Get transaction IDs containing an itemset by intersecting TIDs of individual items.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        itemset : Tuple\n",
    "            The itemset to find transaction IDs for\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Set[int]\n",
    "            Set of transaction IDs containing the itemset\n",
    "        \"\"\"\n",
    "        if len(itemset) == 1:\n",
    "            return self.tid_mapping[itemset[0]]\n",
    "        \n",
    "        # For multiple items, compute intersection of their TIDs\n",
    "        result = self.tid_mapping[itemset[0]]\n",
    "        for item in itemset[1:]:\n",
    "            result = result.intersection(self.tid_mapping[item])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def fit(self, dataset: List[List[Any]]) -> Dict[Tuple, float]:\n",
    "        \"\"\"\n",
    "        Apply the vertical Apriori algorithm to find frequent itemsets.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dataset : List[List[Any]]\n",
    "            List of transactions where each transaction is a list of items\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Dict[Tuple, float]\n",
    "            Dictionary mapping frequent itemsets to their support values\n",
    "        \"\"\"\n",
    "        self.transactions_count = len(dataset)\n",
    "        min_support_count = self.min_support * self.transactions_count\n",
    "        \n",
    "        # Create vertical representation\n",
    "        self.tid_mapping = self._create_vertical_representation(dataset)\n",
    "        \n",
    "        # Find frequent 1-itemsets\n",
    "        freq_1_itemsets = []\n",
    "        support_data = {}\n",
    "        \n",
    "        for item, tids in self.tid_mapping.items():\n",
    "            support = self._get_support(tids)\n",
    "            if support >= self.min_support:\n",
    "                freq_1_itemsets.append((item,))\n",
    "                support_data[(item,)] = support\n",
    "        \n",
    "        self.freq_itemsets.append(freq_1_itemsets)\n",
    "        \n",
    "        k = 2\n",
    "        while self.freq_itemsets[k-2]:\n",
    "            # Generate candidate k-itemsets\n",
    "            candidates = self._generate_candidate_itemsets(self.freq_itemsets[k-2], k)\n",
    "            \n",
    "            # Find frequent k-itemsets\n",
    "            current_freq_itemsets = []\n",
    "            \n",
    "            for candidate in candidates:\n",
    "                # Get transaction IDs containing the candidate\n",
    "                candidate_tids = self._get_transaction_ids(candidate)\n",
    "                support = self._get_support(candidate_tids)\n",
    "                \n",
    "                if support >= self.min_support:\n",
    "                    current_freq_itemsets.append(candidate)\n",
    "                    support_data[candidate] = support\n",
    "            \n",
    "            self.freq_itemsets.append(current_freq_itemsets)\n",
    "            k += 1\n",
    "        \n",
    "        # Remove the last empty list\n",
    "        self.freq_itemsets = self.freq_itemsets[:-1]\n",
    "        \n",
    "        return support_data\n",
    "    \n",
    "    def generate_rules(self, support_data: Dict[Tuple, float], min_confidence: float = 0.7) -> List[Tuple[Tuple, Tuple, float]]:\n",
    "        \"\"\"\n",
    "        Generate association rules from frequent itemsets.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        support_data : Dict[Tuple, float]\n",
    "            Dictionary mapping frequent itemsets to their support values\n",
    "        min_confidence : float\n",
    "            Minimum confidence threshold (between 0 and 1)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        List[Tuple[Tuple, Tuple, float]]\n",
    "            List of rules as (antecedent, consequent, confidence)\n",
    "        \"\"\"\n",
    "        rules = []\n",
    "        \n",
    "        for k in range(1, len(self.freq_itemsets)):\n",
    "            # For each frequent itemset with size > 1\n",
    "            for itemset in self.freq_itemsets[k]:\n",
    "                if len(itemset) > 1:\n",
    "                    # Generate all possible subsets for rules\n",
    "                    for i in range(1, len(itemset)):\n",
    "                        for antecedent in combinations(itemset, i):\n",
    "                            # Convert antecedent to tuple if it's not already\n",
    "                            antecedent_tuple = antecedent if isinstance(antecedent, tuple) else (antecedent,)\n",
    "                            \n",
    "                            # Calculate consequent by removing antecedent items from itemset\n",
    "                            consequent = tuple(item for item in itemset if item not in antecedent)\n",
    "                            \n",
    "                            # Calculate confidence\n",
    "                            confidence = support_data[itemset] / support_data[antecedent_tuple]\n",
    "                            \n",
    "                            if confidence >= min_confidence:\n",
    "                                rules.append((antecedent_tuple, consequent, confidence))\n",
    "        \n",
    "        return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df70ba2a-5e1c-48cf-b5de-e5a9c5f52518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "      0      1       2       3     4      5\n",
      "0  Wine  Chips  Bread   Butter  Milk  Apple\n",
      "1  Wine    NaN  Bread   Butter  Milk    NaN\n",
      "2   NaN    NaN  Bread   Butter  Milk    NaN\n",
      "3   NaN  Chips     NaN     NaN   NaN  Apple\n",
      "4  Wine  Chips  Bread   Butter  Milk  Apple\n",
      "Dataset shape: (22, 6)\n",
      "\n",
      "Transactions format (first 5):\n",
      "Transaction 0: ['Wine', 'Chips', 'Bread ', 'Butter', 'Milk', 'Apple']\n",
      "Transaction 1: ['Wine', 'Bread ', 'Butter', 'Milk']\n",
      "Transaction 2: ['Bread ', 'Butter', 'Milk']\n",
      "Transaction 3: ['Chips', 'Apple']\n",
      "Transaction 4: ['Wine', 'Chips', 'Bread ', 'Butter', 'Milk', 'Apple']\n",
      "Total transactions: 22\n",
      "\n",
      "Running Vertical Apriori with minimum support = 0.6\n",
      "\n",
      "Frequent Itemsets:\n",
      "1-itemsets: 6 found\n",
      "  ('Apple',): support = 0.68 (found in 14 transactions)\n",
      "  ('Bread ',): support = 0.73 (found in 16 transactions)\n",
      "  ('Butter',): support = 0.68 (found in 14 transactions)\n",
      "  ('Chips',): support = 0.64 (found in 14 transactions)\n",
      "  ('Milk',): support = 0.77 (found in 17 transactions)\n",
      "  ('Wine',): support = 0.73 (found in 16 transactions)\n",
      "2-itemsets: 1 found\n",
      "  ('Wine', 'Milk'): support = 0.64 (found in 14 transactions)\n",
      "\n",
      "Generating association rules with minimum confidence = 0.8\n",
      "\n",
      "Association Rules (2 rules found):\n",
      "  Wine => Milk\n",
      "    - confidence: 0.88\n",
      "    - support: 0.64\n",
      "  Milk => Wine\n",
      "    - confidence: 0.82\n",
      "    - support: 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset:\")\n",
    "print(data.head())\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "\n",
    "# Convert the dataset to transaction format (list of lists)\n",
    "transactions = []\n",
    "for _, row in data.iterrows():\n",
    "    # Filter out NaN values and create a list of items\n",
    "    transaction = [item for item in row.values if isinstance(item, str)]\n",
    "    transactions.append(transaction)\n",
    "\n",
    "print(\"\\nTransactions format (first 5):\")\n",
    "for i, transaction in enumerate(transactions[:5]):\n",
    "    print(f\"Transaction {i}: {transaction}\")\n",
    "\n",
    "print(f\"Total transactions: {len(transactions)}\")\n",
    "\n",
    "# Create and run the Vertical Apriori algorithm\n",
    "min_support = 0.6  # 60% minimum support\n",
    "print(f\"\\nRunning Vertical Apriori with minimum support = {min_support}\")\n",
    "apriori = VerticalApriori(min_support=min_support)\n",
    "support_data = apriori.fit(transactions)\n",
    "\n",
    "# Print frequent itemsets by size\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "for k, itemsets in enumerate(apriori.freq_itemsets):\n",
    "    print(f\"{k+1}-itemsets: {len(itemsets)} found\")\n",
    "    for itemset in sorted(itemsets):\n",
    "        support = support_data[itemset]\n",
    "        count = int(support * len(transactions))\n",
    "        print(f\"  {itemset}: support = {support:.2f} (found in {count} transactions)\")\n",
    "\n",
    "# Generate association rules with 80% minimum confidence\n",
    "min_confidence = 0.8\n",
    "print(f\"\\nGenerating association rules with minimum confidence = {min_confidence}\")\n",
    "rules = apriori.generate_rules(support_data, min_confidence=min_confidence)\n",
    "\n",
    "# Print association rules\n",
    "if rules:\n",
    "    print(f\"\\nAssociation Rules ({len(rules)} rules found):\")\n",
    "    # Sort rules by confidence\n",
    "    sorted_rules = sorted(rules, key=lambda x: x[2], reverse=True)\n",
    "    for antecedent, consequent, confidence in sorted_rules:\n",
    "        combined = antecedent + consequent\n",
    "        support = support_data.get(combined, 0)\n",
    "        consequent_str = ', '.join(consequent)\n",
    "        antecedent_str = ', '.join(antecedent)\n",
    "        print(f\"  {antecedent_str} => {consequent_str}\")\n",
    "        print(f\"    - confidence: {confidence:.2f}\")\n",
    "        print(f\"    - support: {support:.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo association rules found with the given confidence threshold.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
