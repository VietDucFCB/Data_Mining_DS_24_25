{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9843b6-399f-4083-8136-2fdbc1cdf429",
   "metadata": {},
   "source": [
    "# DATA MINING - WEEK 4\n",
    "## NGUYEN XUAN VIET DUC - 22280012\n",
    "### Lesson 4: Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387f280-f1d4-4207-9796-201a5a881565",
   "metadata": {},
   "source": [
    "### I. Objectives:\n",
    "- Apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c400cd-a9af-4471-9eb7-c8378534caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kkagi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c83da4-45a3-428b-959c-dab69da15cbb",
   "metadata": {},
   "source": [
    "## II. Practice content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7851ae3c-d5fb-472d-b720-bb8a15c8a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1       2       3     4      5\n",
      "0   Wine  Chips  Bread   Butter  Milk  Apple\n",
      "1   Wine    NaN  Bread   Butter  Milk    NaN\n",
      "2    NaN    NaN  Bread   Butter  Milk    NaN\n",
      "3    NaN  Chips     NaN     NaN   NaN  Apple\n",
      "4   Wine  Chips  Bread   Butter  Milk  Apple\n",
      "5   Wine  Chips     NaN     NaN  Milk    NaN\n",
      "6   Wine  Chips  Bread   Butter   NaN  Apple\n",
      "7   Wine  Chips     NaN     NaN  Milk    NaN\n",
      "8   Wine    NaN  Bread      NaN   NaN  Apple\n",
      "9   Wine    NaN  Bread   Butter  Milk    NaN\n",
      "10   NaN  Chips  Bread   Butter   NaN  Apple\n",
      "11  Wine    NaN     NaN  Butter  Milk  Apple\n",
      "12  Wine  Chips  Bread   Butter  Milk    NaN\n",
      "13  Wine    NaN  Bread      NaN  Milk  Apple\n",
      "14  Wine    NaN  Bread   Butter  Milk  Apple\n",
      "15  Wine  Chips  Bread   Butter  Milk  Apple\n",
      "16   NaN  Chips  Bread   Butter  Milk  Apple\n",
      "17   NaN  Chips     NaN  Butter  Milk  Apple\n",
      "18  Wine  Chips  Bread   Butter  Milk  Apple\n",
      "19  Wine    NaN  Bread   Butter  Milk  Apple\n",
      "20  Wine  Chips  Bread      NaN  Milk  Apple\n",
      "21   NaN  Chips     NaN     NaN   NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from itertools import combinations\n",
    "from mlxtend.frequent_patterns import apriori as mlxtend_apriori\n",
    "from mlxtend.frequent_patterns import association_rules as mlxtend_association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load dữ liệu\n",
    "df = pd.read_csv('dataW4.csv', header=None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3134b0b2-58d2-40e0-b69a-331d2c3dd7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "\n",
    "records = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    records.append([str(data.values[i,j]) for j in range(0, data.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6c9f4d-92d4-4647-98ee-f9838b8e1842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Apple  Bread   Butter  Chips   Milk   Wine    nan\n",
      "0    True    True    True   True   True   True  False\n",
      "1   False    True    True  False   True   True   True\n",
      "2   False    True    True  False   True  False   True\n",
      "3    True   False   False   True  False  False   True\n",
      "4    True    True    True   True   True   True  False\n",
      "5   False   False   False   True   True   True   True\n",
      "6    True    True    True   True  False   True   True\n",
      "7   False   False   False   True   True   True   True\n",
      "8    True    True   False  False  False   True   True\n",
      "9   False    True    True  False   True   True   True\n",
      "10   True    True    True   True  False  False   True\n",
      "11   True   False    True  False   True   True   True\n",
      "12  False    True    True   True   True   True   True\n",
      "13   True    True   False  False   True   True   True\n",
      "14   True    True    True  False   True   True   True\n",
      "15   True    True    True   True   True   True  False\n",
      "16   True    True    True   True   True  False   True\n",
      "17   True   False    True   True   True  False   True\n",
      "18   True    True    True   True   True   True  False\n",
      "19   True    True    True  False   True   True   True\n",
      "20   True    True   False   True   True   True   True\n",
      "21  False   False   False   True  False  False   True\n"
     ]
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records)\n",
    "df1 = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85a4abb-3e4f-45c9-a209-a881e86fe37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    support      itemsets\n",
      "0  0.681818       (Apple)\n",
      "1  0.727273      (Bread )\n",
      "2  0.681818      (Butter)\n",
      "3  0.636364       (Chips)\n",
      "4  0.772727        (Milk)\n",
      "5  0.727273        (Wine)\n",
      "6  0.818182         (nan)\n",
      "7  0.636364  (Wine, Milk)\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(df1, min_support=0.6, use_colnames=True)\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f498226-6eb1-4ad7-88e0-06ed31b9db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents   support\n",
      "0      (Wine)      (Milk)  0.636364\n",
      "1      (Milk)      (Wine)  0.636364\n"
     ]
    }
   ],
   "source": [
    "rules = association_rules(frequent_itemsets, metric='support', support_only=True, min_threshold=0.1)\n",
    "rules = rules[['antecedents', 'consequents', 'support']]\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ed34ba-b047-4978-b3d0-1ec8b12a8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AprioriAlgorithm:\n",
    "    def __init__(self, min_support=0.5, min_confidence=0.7):\n",
    "        self.min_support = min_support\n",
    "        self.min_confidence = min_confidence\n",
    "        self.itemsets = {}\n",
    "        self.rules = []\n",
    "        self.item_counts = {}\n",
    "        self.itemset_counts = {} \n",
    "    \n",
    "    def fit(self, transactions):\n",
    "\n",
    "        self.transactions = transactions\n",
    "        self.n_transactions = len(transactions)\n",
    "        \n",
    "        # Find frequent 1-itemsets\n",
    "        self._find_frequent_1_itemsets()\n",
    "        self.print_frequent_1_itemsets()\n",
    "        \n",
    "        k = 2\n",
    "        while True:\n",
    "            if k-1 not in self.itemsets or not self.itemsets[k-1]:\n",
    "                break\n",
    "                \n",
    "            candidate_itemsets = self._generate_candidate_itemsets(k)\n",
    "            if not candidate_itemsets:\n",
    "                break\n",
    "                \n",
    "            self.print_candidate_itemsets(k, candidate_itemsets)\n",
    "                \n",
    "            self.itemset_counts[k] = self._count_itemsets(candidate_itemsets)\n",
    "            \n",
    "            self.itemsets[k] = {itemset: count / self.n_transactions \n",
    "                               for itemset, count in self.itemset_counts[k].items() \n",
    "                               if count / self.n_transactions >= self.min_support}\n",
    "            \n",
    "            self.print_frequent_k_itemsets(k)\n",
    "            \n",
    "            k += 1\n",
    "            \n",
    "        self._generate_rules()\n",
    "        self.print_rules()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _find_frequent_1_itemsets(self):\n",
    "        self.item_counts = {}\n",
    "        \n",
    "        for transaction in self.transactions:\n",
    "            for item in transaction:\n",
    "                if item in self.item_counts:\n",
    "                    self.item_counts[item] += 1\n",
    "                else:\n",
    "                    self.item_counts[item] = 1\n",
    "        \n",
    "        self.itemsets[1] = {frozenset([item]): count / self.n_transactions \n",
    "                           for item, count in self.item_counts.items() \n",
    "                           if count / self.n_transactions >= self.min_support}\n",
    "    \n",
    "    def _generate_candidate_itemsets(self, k):\n",
    "        \n",
    "        candidates = set()\n",
    "        prev_itemsets = list(self.itemsets[k-1].keys())\n",
    "        \n",
    "        for i in range(len(prev_itemsets)):\n",
    "            for j in range(i+1, len(prev_itemsets)):\n",
    "                itemset1 = sorted(list(prev_itemsets[i]))\n",
    "                itemset2 = sorted(list(prev_itemsets[j]))\n",
    "\n",
    "                if k == 2:\n",
    "                    new_itemset = frozenset(itemset1 + itemset2)\n",
    "                    if len(new_itemset) == k:\n",
    "                        candidates.add(new_itemset)\n",
    "                else:\n",
    "                    if itemset1[:-1] == itemset2[:-1]:\n",
    "                        new_itemset = frozenset(itemset1 + [itemset2[-1]])\n",
    "\n",
    "                        if self._all_subsets_frequent(new_itemset, k-1):\n",
    "                            candidates.add(new_itemset)\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def _all_subsets_frequent(self, itemset, k):\n",
    "        \n",
    "        for subset in combinations(itemset, k):\n",
    "            if frozenset(subset) not in self.itemsets[k]:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _count_itemsets(self, candidate_itemsets):\n",
    "\n",
    "        itemset_counts = {itemset: 0 for itemset in candidate_itemsets}\n",
    "        \n",
    "        for transaction in self.transactions:\n",
    "            transaction_set = set(transaction)\n",
    "            for itemset in candidate_itemsets:\n",
    "                if all(item in transaction_set for item in itemset):\n",
    "                    itemset_counts[itemset] += 1\n",
    "                    \n",
    "        return itemset_counts\n",
    "    \n",
    "    def _generate_rules(self):\n",
    "\n",
    "        self.rules = []\n",
    "        \n",
    "        for k in range(2, len(self.itemsets) + 1):\n",
    "            if k not in self.itemsets:\n",
    "                continue\n",
    "                \n",
    "            for itemset, support in self.itemsets[k].items():\n",
    "                for i in range(1, k):\n",
    "                    for antecedent in combinations(itemset, i):\n",
    "                        antecedent = frozenset(antecedent)\n",
    "                        consequent = frozenset(itemset - antecedent)\n",
    "                        \n",
    "                        confidence = support / self.itemsets[len(antecedent)][antecedent]\n",
    "                        \n",
    "                        if confidence >= self.min_confidence:\n",
    "                            self.rules.append({\n",
    "                                'antecedent': list(antecedent),\n",
    "                                'consequent': list(consequent),\n",
    "                                'support': support,\n",
    "                                'confidence': confidence\n",
    "                            })\n",
    "    \n",
    "    def get_itemsets(self):\n",
    "        result = []\n",
    "        for k in self.itemsets:\n",
    "            for itemset, support in self.itemsets[k].items():\n",
    "                result.append({\n",
    "                    'itemset': list(itemset),\n",
    "                    'support': support\n",
    "                })\n",
    "        return result\n",
    "    \n",
    "    def get_rules(self):\n",
    "        return self.rules\n",
    "    \n",
    "\n",
    "    def print_frequent_1_itemsets(self):\n",
    "        print(\"\\n- Với k = 1, ta khởi tạo F1\")\n",
    "        print(\"Item\\t\\tfrequency\\tsupport\")\n",
    "        for item, count in sorted(self.item_counts.items()):\n",
    "            if count / self.n_transactions >= self.min_support:\n",
    "                support_pct = count / self.n_transactions * 100\n",
    "                print(f\"{item}\\t\\t{count}\\t\\t{support_pct:.0f}%\")\n",
    "    \n",
    "    def print_candidate_itemsets(self, k, candidates):\n",
    "        print(f\"\\n- Khởi tạo C{k} bằng việc kết hợp các cặp item của F{k-1}\")\n",
    "        candidate_str = \", \".join([str(list(c)) for c in candidates])\n",
    "        print(f\"{candidate_str}\")\n",
    "    \n",
    "    def print_frequent_k_itemsets(self, k):\n",
    "        print(f\"\\n- Tạo F{k}\")\n",
    "        print(\"Item\\t\\t\\tfrequency\\tsupport\")\n",
    "        \n",
    "        for itemset in sorted(self.itemset_counts[k].keys(), key=lambda x: tuple(sorted(x))):\n",
    "            count = self.itemset_counts[k][itemset]\n",
    "            support_pct = count / self.n_transactions * 100\n",
    "            items_str = \", \".join(sorted(itemset))\n",
    "            print(f\"{items_str}\\t\\t{count}\\t\\t{support_pct:.0f}%\")\n",
    "        \n",
    "        print(f\"\\n- Tìm các hạng mục quan trọng dựa vào minsup = {self.min_support*100:.0f}% nên ta lấy các {k}-item sau:\")\n",
    "        important_itemsets = [list(itemset) for itemset in self.itemsets[k].keys()]\n",
    "        if important_itemsets:\n",
    "            print(f\"{important_itemsets}\")\n",
    "        else:\n",
    "            print(f\"F{k} = ∅\")\n",
    "    \n",
    "    def print_rules(self):\n",
    "        print(\"\\n- Phát sinh các luật\")\n",
    "        for rule in self.rules:\n",
    "            antecedent = \", \".join(rule['antecedent'])\n",
    "            consequent = \", \".join(rule['consequent'])\n",
    "            support = rule['support']\n",
    "            confidence = rule['confidence']\n",
    "            \n",
    "            print(f\"{antecedent} → {consequent} có conf({antecedent} → {consequent}) = support({antecedent}, {consequent})/support({antecedent}) = {confidence*100:.0f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "096c07ef-9753-48fb-ac45-14486d8db0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21 transactions from dataW4.csv\n",
      "Sample of transactions:\n",
      "Transaction 1: ['Wine', 'Bread ', 'Butter', 'Milk']\n",
      "Transaction 2: ['Bread ', 'Butter', 'Milk']\n",
      "Transaction 3: ['Chips', 'Apple']\n",
      "Transaction 4: ['Wine', 'Chips', 'Bread ', 'Butter', 'Milk', 'Apple']\n",
      "Transaction 5: ['Wine', 'Chips', 'Milk']\n",
      "\n",
      "Running Apriori with min_support=60% and min_confidence=80%\n",
      "\n",
      "- Với k = 1, ta khởi tạo F1\n",
      "Item\t\tfrequency\tsupport\n",
      "Apple\t\t14\t\t67%\n",
      "Bread \t\t15\t\t71%\n",
      "Butter\t\t14\t\t67%\n",
      "Chips\t\t13\t\t62%\n",
      "Milk\t\t16\t\t76%\n",
      "Wine\t\t15\t\t71%\n",
      "\n",
      "- Khởi tạo C2 bằng việc kết hợp các cặp item của F1\n",
      "['Milk', 'Apple'], ['Butter', 'Milk'], ['Butter', 'Chips'], ['Wine', 'Chips'], ['Bread ', 'Milk'], ['Bread ', 'Chips'], ['Wine', 'Milk'], ['Bread ', 'Apple'], ['Chips', 'Apple'], ['Wine', 'Apple'], ['Butter', 'Bread '], ['Butter', 'Apple'], ['Chips', 'Milk'], ['Bread ', 'Wine'], ['Butter', 'Wine']\n",
      "\n",
      "- Tạo F2\n",
      "Item\t\t\tfrequency\tsupport\n",
      "Apple, Bread \t\t11\t\t52%\n",
      "Apple, Butter\t\t10\t\t48%\n",
      "Apple, Chips\t\t9\t\t43%\n",
      "Apple, Milk\t\t10\t\t48%\n",
      "Apple, Wine\t\t10\t\t48%\n",
      "Bread , Butter\t\t12\t\t57%\n",
      "Bread , Chips\t\t8\t\t38%\n",
      "Bread , Milk\t\t12\t\t57%\n",
      "Bread , Wine\t\t12\t\t57%\n",
      "Butter, Chips\t\t8\t\t38%\n",
      "Butter, Milk\t\t12\t\t57%\n",
      "Butter, Wine\t\t10\t\t48%\n",
      "Chips, Milk\t\t9\t\t43%\n",
      "Chips, Wine\t\t8\t\t38%\n",
      "Milk, Wine\t\t13\t\t62%\n",
      "\n",
      "- Tìm các hạng mục quan trọng dựa vào minsup = 60% nên ta lấy các 2-item sau:\n",
      "[['Wine', 'Milk']]\n",
      "\n",
      "- Phát sinh các luật\n",
      "Wine → Milk có conf(Wine → Milk) = support(Wine, Milk)/support(Wine) = 87%\n",
      "Milk → Wine có conf(Milk → Wine) = support(Milk, Wine)/support(Milk) = 81%\n",
      "\n",
      "==================================================\n",
      "SO SÁNH IMPLEMENTATION TỰ VIẾT VỚI THƯ VIỆN MLXTEND\n",
      "==================================================\n",
      "\n",
      "1. IMPLEMENTATION TỰ VIẾT\n",
      "\n",
      "- Với k = 1, ta khởi tạo F1\n",
      "Item\t\tfrequency\tsupport\n",
      "Apple\t\t14\t\t67%\n",
      "Bread \t\t15\t\t71%\n",
      "Butter\t\t14\t\t67%\n",
      "Chips\t\t13\t\t62%\n",
      "Milk\t\t16\t\t76%\n",
      "Wine\t\t15\t\t71%\n",
      "\n",
      "- Khởi tạo C2 bằng việc kết hợp các cặp item của F1\n",
      "['Milk', 'Apple'], ['Butter', 'Milk'], ['Butter', 'Chips'], ['Wine', 'Chips'], ['Bread ', 'Milk'], ['Bread ', 'Chips'], ['Wine', 'Milk'], ['Bread ', 'Apple'], ['Chips', 'Apple'], ['Wine', 'Apple'], ['Butter', 'Bread '], ['Butter', 'Apple'], ['Chips', 'Milk'], ['Bread ', 'Wine'], ['Butter', 'Wine']\n",
      "\n",
      "- Tạo F2\n",
      "Item\t\t\tfrequency\tsupport\n",
      "Apple, Bread \t\t11\t\t52%\n",
      "Apple, Butter\t\t10\t\t48%\n",
      "Apple, Chips\t\t9\t\t43%\n",
      "Apple, Milk\t\t10\t\t48%\n",
      "Apple, Wine\t\t10\t\t48%\n",
      "Bread , Butter\t\t12\t\t57%\n",
      "Bread , Chips\t\t8\t\t38%\n",
      "Bread , Milk\t\t12\t\t57%\n",
      "Bread , Wine\t\t12\t\t57%\n",
      "Butter, Chips\t\t8\t\t38%\n",
      "Butter, Milk\t\t12\t\t57%\n",
      "Butter, Wine\t\t10\t\t48%\n",
      "Chips, Milk\t\t9\t\t43%\n",
      "Chips, Wine\t\t8\t\t38%\n",
      "Milk, Wine\t\t13\t\t62%\n",
      "\n",
      "- Tìm các hạng mục quan trọng dựa vào minsup = 60% nên ta lấy các 2-item sau:\n",
      "[['Wine', 'Milk']]\n",
      "\n",
      "- Phát sinh các luật\n",
      "Wine → Milk có conf(Wine → Milk) = support(Wine, Milk)/support(Wine) = 87%\n",
      "Milk → Wine có conf(Milk → Wine) = support(Milk, Wine)/support(Milk) = 81%\n",
      "\n",
      "2. IMPLEMENTATION THƯ VIỆN MLXTEND\n",
      "\n",
      "3. KẾT QUẢ SO SÁNH\n",
      "- Thời gian thực thi:\n",
      "  - Implementation tự viết: 0.0000 giây\n",
      "  - Thư viện mlxtend: 0.0070 giây\n",
      "\n",
      "- Số lượng itemsets:\n",
      "  - Implementation tự viết: 7\n",
      "  - Thư viện mlxtend: 7\n",
      "\n",
      "- Số lượng luật:\n",
      "  - Implementation tự viết: 2\n",
      "  - Thư viện mlxtend: 2\n",
      "\n",
      "- Kết quả có trùng khớp không:\n",
      "  - Itemsets: Có\n",
      "  - Luật: Có\n",
      "\n",
      "4. MẪU CÁC ITEMSETS TÌM ĐƯỢC\n",
      "- Implementation tự viết (top 5):\n",
      "  1. ['Milk'] (support: 0.7619)\n",
      "  2. ['Wine'] (support: 0.7143)\n",
      "  3. ['Bread '] (support: 0.7143)\n",
      "  4. ['Butter'] (support: 0.6667)\n",
      "  5. ['Apple'] (support: 0.6667)\n",
      "\n",
      "- Thư viện mlxtend (top 5):\n",
      "  1. ['Milk'] (support: 0.7619)\n",
      "  2. ['Bread '] (support: 0.7143)\n",
      "  3. ['Wine'] (support: 0.7143)\n",
      "  4. ['Apple'] (support: 0.6667)\n",
      "  5. ['Butter'] (support: 0.6667)\n",
      "\n",
      "5. MẪU CÁC LUẬT KẾT HỢP TÌM ĐƯỢC\n",
      "- Implementation tự viết (top 5):\n",
      "  1. ['Wine'] → ['Milk'] (support: 0.6190, confidence: 0.8667)\n",
      "  2. ['Milk'] → ['Wine'] (support: 0.6190, confidence: 0.8125)\n",
      "\n",
      "- Thư viện mlxtend (top 5):\n",
      "  1. ['Wine'] → ['Milk'] (support: 0.6190, confidence: 0.8667)\n",
      "  2. ['Milk'] → ['Wine'] (support: 0.6190, confidence: 0.8125)\n",
      "\n",
      "6. KẾT LUẬN\n",
      "- Implementation tự viết cho kết quả trùng khớp với thư viện mlxtend\n",
      "- Thời gian thực thi quá nhanh để so sánh chính xác\n",
      "\n",
      "=== Summary of Results ===\n",
      "Total transactions processed: 21\n",
      "Total frequent itemsets found: 7\n",
      "Total association rules found: 2\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_csv(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    transactions = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Filter out NaN values and convert to list\n",
    "        transaction = [item for item in row if pd.notna(item)]\n",
    "        transactions.append(transaction)\n",
    "    \n",
    "    print(f\"Loaded {len(transactions)} transactions from {file_path}\")\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def run_mlxtend_apriori(transactions, min_support=0.6, min_confidence=0.8):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    # Find frequent itemsets\n",
    "    frequent_itemsets = mlxtend_apriori(df, min_support=min_support, use_colnames=True)\n",
    "    \n",
    "    # Generate rules\n",
    "    rules = mlxtend_association_rules(frequent_itemsets, metric=\"confidence\", \n",
    "                                     min_threshold=min_confidence)\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    return frequent_itemsets, rules, execution_time\n",
    "\n",
    "\n",
    "def compare_implementations(transactions, min_support=0.6, min_confidence=0.8):\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SO SÁNH IMPLEMENTATION TỰ VIẾT VỚI THƯ VIỆN MLXTEND\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\n1. IMPLEMENTATION TỰ VIẾT\")\n",
    "    custom_start_time = time.time()\n",
    "    custom_apriori = AprioriAlgorithm(min_support=min_support, min_confidence=min_confidence)\n",
    "    custom_apriori.fit(transactions)\n",
    "    custom_time = time.time() - custom_start_time\n",
    "    \n",
    "    custom_itemsets = custom_apriori.get_itemsets()\n",
    "    custom_rules = custom_apriori.get_rules()\n",
    "    \n",
    "    print(\"\\n2. IMPLEMENTATION THƯ VIỆN MLXTEND\")\n",
    "    mlxtend_itemsets, mlxtend_rules, mlxtend_time = run_mlxtend_apriori(\n",
    "        transactions, min_support, min_confidence\n",
    "    )\n",
    "    \n",
    "    mlxtend_itemsets_converted = []\n",
    "    for _, row in mlxtend_itemsets.iterrows():\n",
    "        itemset = list(row['itemsets'])\n",
    "        support = row['support']\n",
    "        mlxtend_itemsets_converted.append({\n",
    "            'itemset': itemset,\n",
    "            'support': support\n",
    "        })\n",
    "    \n",
    "    mlxtend_rules_converted = []\n",
    "    for _, row in mlxtend_rules.iterrows():\n",
    "        mlxtend_rules_converted.append({\n",
    "            'antecedent': list(row['antecedents']),\n",
    "            'consequent': list(row['consequents']),\n",
    "            'support': row['support'],\n",
    "            'confidence': row['confidence']\n",
    "        })\n",
    "    \n",
    "    print(\"\\n3. KẾT QUẢ SO SÁNH\")\n",
    "    print(f\"- Thời gian thực thi:\")\n",
    "    print(f\"  - Implementation tự viết: {custom_time:.4f} giây\")\n",
    "    print(f\"  - Thư viện mlxtend: {mlxtend_time:.4f} giây\")\n",
    "    \n",
    "    print(f\"\\n- Số lượng itemsets:\")\n",
    "    print(f\"  - Implementation tự viết: {len(custom_itemsets)}\")\n",
    "    print(f\"  - Thư viện mlxtend: {len(mlxtend_itemsets_converted)}\")\n",
    "    \n",
    "    print(f\"\\n- Số lượng luật:\")\n",
    "    print(f\"  - Implementation tự viết: {len(custom_rules)}\")\n",
    "    print(f\"  - Thư viện mlxtend: {len(mlxtend_rules_converted)}\")\n",
    "    \n",
    "    # Check if results match\n",
    "    itemsets_match = len(custom_itemsets) == len(mlxtend_itemsets_converted)\n",
    "    rules_match = len(custom_rules) == len(mlxtend_rules_converted)\n",
    "    \n",
    "    print(f\"\\n- Kết quả có trùng khớp không:\")\n",
    "    print(f\"  - Itemsets: {'Có' if itemsets_match else 'Không'}\")\n",
    "    print(f\"  - Luật: {'Có' if rules_match else 'Không'}\")\n",
    "    \n",
    "    print(\"\\n4. MẪU CÁC ITEMSETS TÌM ĐƯỢC\")\n",
    "    print(\"- Implementation tự viết (top 5):\")\n",
    "    for i, item in enumerate(sorted(custom_itemsets, key=lambda x: x['support'], reverse=True)[:5]):\n",
    "        print(f\"  {i+1}. {item['itemset']} (support: {item['support']:.4f})\")\n",
    "    \n",
    "    print(\"\\n- Thư viện mlxtend (top 5):\")\n",
    "    for i, item in enumerate(sorted(mlxtend_itemsets_converted, key=lambda x: x['support'], reverse=True)[:5]):\n",
    "        print(f\"  {i+1}. {item['itemset']} (support: {item['support']:.4f})\")\n",
    "    \n",
    "    print(\"\\n5. MẪU CÁC LUẬT KẾT HỢP TÌM ĐƯỢC\")\n",
    "    print(\"- Implementation tự viết (top 5):\")\n",
    "    for i, rule in enumerate(sorted(custom_rules, key=lambda x: x['confidence'], reverse=True)[:5]):\n",
    "        print(f\"  {i+1}. {rule['antecedent']} → {rule['consequent']} \"\n",
    "              f\"(support: {rule['support']:.4f}, confidence: {rule['confidence']:.4f})\")\n",
    "    \n",
    "    print(\"\\n- Thư viện mlxtend (top 5):\")\n",
    "    for i, rule in enumerate(sorted(mlxtend_rules_converted, key=lambda x: x['confidence'], reverse=True)[:5]):\n",
    "        print(f\"  {i+1}. {rule['antecedent']} → {rule['consequent']} \"\n",
    "              f\"(support: {rule['support']:.4f}, confidence: {rule['confidence']:.4f})\")\n",
    "    \n",
    "    print(\"\\n6. KẾT LUẬN\")\n",
    "    if itemsets_match and rules_match:\n",
    "        print(\"- Implementation tự viết cho kết quả trùng khớp với thư viện mlxtend\")\n",
    "        # Fix the division by zero error\n",
    "        if custom_time <= 0 or mlxtend_time <= 0:\n",
    "            print(\"- Thời gian thực thi quá nhanh để so sánh chính xác\")\n",
    "        elif custom_time < mlxtend_time:\n",
    "            print(f\"- Implementation tự viết nhanh hơn {(mlxtend_time/custom_time):.2f} lần so với thư viện mlxtend\")\n",
    "        else:\n",
    "            print(f\"- Thư viện mlxtend nhanh hơn {(custom_time/mlxtend_time):.2f} lần so với implementation tự viết\")\n",
    "    else:\n",
    "        print(\"- Implementation tự viết cho kết quả khác với thư viện mlxtend\")\n",
    "        print(\"- Cần kiểm tra lại thuật toán hoặc các tham số đầu vào\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    csv_file = \"dataW4.csv\"\n",
    "    transactions = load_data_from_csv(csv_file)\n",
    "    \n",
    "    print(\"Sample of transactions:\")\n",
    "    for i, transaction in enumerate(transactions[:5]):\n",
    "        print(f\"Transaction {i+1}: {transaction}\")\n",
    "    \n",
    "    min_support = 0.6\n",
    "    min_confidence = 0.8\n",
    "    \n",
    "    print(f\"\\nRunning Apriori with min_support={min_support*100:.0f}% and min_confidence={min_confidence*100:.0f}%\")\n",
    "    \n",
    "    apriori = AprioriAlgorithm(min_support=min_support, min_confidence=min_confidence)\n",
    "    apriori.fit(transactions)\n",
    "\n",
    "    compare_implementations(transactions, min_support, min_confidence)\n",
    "\n",
    "    print(\"\\n=== Summary of Results ===\")\n",
    "    print(f\"Total transactions processed: {len(transactions)}\")\n",
    "    print(f\"Total frequent itemsets found: {sum(len(itemsets) for itemsets in apriori.itemsets.values())}\")\n",
    "    print(f\"Total association rules found: {len(apriori.rules)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dde496-2e12-478c-bb17-9a6f15277cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
